import json
import requests
from tqdm import tqdm
from urllib.parse import urlparse
from utils import contain_str
origin_booksource = "./exportRssSource.json"

with open(origin_booksource, encoding="utf-8") as f:
    origin_dict = json.load(f)

check_list = [[], []]   # Grounp åŸŸå
result = []
for item in tqdm(origin_dict):
    sourceGroup = item.get("sourceGroup","")
    sourceUrl = item["sourceUrl"]
    sourceName = item["sourceName"]
    tool_group = ["aiå·¥å…·é›†", "å·¥å…·", "âš™ï¸å·¥å…·", "å›¾ç‰‡", "ai", "AI", 'âœï¸ è®¾è®¡', 'ğŸ“± èµ„æº', 'ã€½ï¸ åˆ›æ„', 'ğŸŒ å›¾æ–‡', 'ğŸ“¥ ä¸‹è½½']
    meiti_group =['ğŸ¶ éŸ³ä¹', 'ğŸ“» éŸ³é¢‘']
    game_group =["æ¸¸æˆ", "4399"]
    video_group =["ğŸ“º å½±è§†", 'ğŸï¸ è§†é¢‘','ğŸ¬ å¤§é™†', 'ğŸ¬ ç›´æ’­', 'ğŸ¬ å½±è§†', "å½±è§†", "åª’ä½“"]
    soft_group = ["è½¯ä»¶", "csdn"]
    zixun_group = ['ğŸŒ æ–°é—»', 'ğŸ‘» å¼‚é—»', 'ğŸ›°ï¸ ç§‘æŠ€', "æ–°é—»"]
    chengren_group = ['18ç¦', 'Â®å…ç¿»,18ç¦', 'Â®å…ç¿»,18ç¦', "18", "ç¾å›¾", "ğŸ”","ç‰¹æ®Š", "Aå§", "MISSAV"]
    yuedu_group = ['legado', 'ğŸ“– ä¹¦æº', 'ğŸ“š ä¹¦å•', '1', "ğŸ“®ä¸ä¼¼è‹", "å¤è¯—", "â“ªæ•´åˆ", "è®¢é˜…" ]
    yuedu_name = ['legado', "ä¹¦æº", "çŸ¥ä¹", "ç»"]
        
    if contain_str(sourceGroup, tool_group):
        item["sourceGroup"] = "âš™ï¸ å·¥å…·"
    elif contain_str(sourceGroup, meiti_group):
        item["sourceGroup"] = 'ğŸ“» åª’ä½“'
    elif contain_str(sourceGroup, game_group):
        item["sourceGroup"] = "ğŸ² å¨±ä¹"
    elif contain_str(sourceGroup, video_group):
        item["sourceGroup"] = "ğŸï¸ å½±è§†"
    elif contain_str(sourceGroup, soft_group):
        item["sourceGroup"] = "ğŸ—‚ï¸ è½¯ä»¶"
    elif contain_str(sourceGroup, zixun_group):
        item["sourceGroup"] = 'ğŸ“° èµ„è®¯'
    elif contain_str(sourceGroup, chengren_group):
        item["sourceGroup"] = 'ğŸ¬ 18ç¦'
    elif contain_str(sourceGroup, yuedu_group) or contain_str(sourceName, yuedu_name):
        item["sourceGroup"] = 'ğŸ“– é˜…è¯»'
    else:
        print("======sourceGroup:{}======sourceName:{}".format(sourceGroup, sourceName))
        item["sourceGroup"] = 'ğŸ’  å…¶ä»–'

    domain = urlparse(sourceUrl).netloc
    if domain not in check_list[1]:
        check_list[1].append(domain)
    else:
        continue

    if sourceGroup not in check_list[0]:
        check_list[0].append(sourceGroup)
    sourceName_list = list(sourceName)

    for i in range(len(sourceName_list)):
        try:
            ch = sourceName_list[i]
            if '\u4e00' <= ch <= '\u9fff' or '0' <= ch <= '9' or 'a' <= ch <= 'z' or 'A' <= ch <= 'Z':
                break
            sourceName_list= sourceName_list[i:]
        except Exception as e:
            print(e)
            print(sourceName)
            print(i)
    sourceName = "".join(sourceName_list)
    sourceName =sourceName.strip()
    item["sourceName"] = sourceName.replace(" ", "")

    result.append(item)
print(check_list[0])

with open(origin_booksource.replace("json","new.json"), encoding="utf-8", mode="w") as f:
    result = json.dump(result, f, ensure_ascii=False, indent=2)